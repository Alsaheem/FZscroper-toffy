{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy and paste the link here to generate a dowload link::: https://fzmovies.net/movie-TheTwilightSaga:BreakingDawn-Part2--hmp4.htm\n",
      "\n",
      "\n",
      "if you did not coppy this link well this code will break\n",
      "\n",
      "\n",
      "https://fzmovies.net/movie-TheTwilightSaga:BreakingDawn-Part2--hmp4.htm\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5b4409d67423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#raw url for download page1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mdown_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_page\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;31m#action to open url for downoad page 1, with http appended to it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdown_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import mechanize\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "    #to initialize the browser\n",
    "br = mechanize.Browser()\n",
    "br.set_handle_robots(False)\n",
    "br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]\n",
    "\n",
    "\n",
    "####################################DETAIL PAGE#######\n",
    "\n",
    "detail = input('copy and paste the link here to generate a dowload link::: ')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#this eliminates all the white spaces and replace then with 20% in accordance to fzmovies url pattern\n",
    "\n",
    "print('if you did not coppy this link well this code will break')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(detail)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "#r = requests.get(detail)\n",
    "\n",
    "#for opening detail page\n",
    "r = br.open(detail)\n",
    "\n",
    "#to read and save the page\n",
    "orders_html = br.response().read()\n",
    "\n",
    "soup = BeautifulSoup(orders_html,'html.parser')\n",
    "\n",
    "#filltering ul \n",
    "divs = soup.find_all(\"ul\", {\"class\": \"moviesfiles\"})\n",
    "\n",
    "#initializing an empty array\n",
    "li = []\n",
    "\n",
    "#  this for loop is for filltering all a tags in the ul tag fillltered before and appending the results to a new array\n",
    "for d in divs:\n",
    "\tul = d.find_all('a', href=True)\n",
    "\tfor u in ul:\n",
    "\t\tli.append(u['href'])\n",
    "\t\t\n",
    "\n",
    "#initializing a new array\n",
    "down_page = []\n",
    "\n",
    "\n",
    "#this for loop is to remove the media.php in the link array and form the download page link\n",
    "for i in li:\n",
    "    if 'mediainfo.php' in i:\n",
    "        del i\n",
    "    else:\n",
    "        down_page.append('fzmovies.net/'+str(i))\n",
    "        \n",
    "\n",
    "#raw url for download page1\n",
    "down_conf = down_page[0]\n",
    "#action to open url for downoad page 1, with http appended to it\n",
    "r = br.open('https://'+down_conf)\n",
    "\n",
    "\n",
    "\n",
    "orders_html = br.response().read()\n",
    "\n",
    "soup = BeautifulSoup(orders_html,'html.parser')\n",
    "\n",
    "divs = soup.find_all(\"a\", {\"id\": \"downloadlink\"})\n",
    "\n",
    "nexts = []\n",
    "for d in divs:\n",
    "        nexts.append(d['href'])\n",
    "        maybe = d['href']\n",
    "        down_page_2 = 'https://fzmovies.net/'+maybe\n",
    "\n",
    "        \n",
    "######Entering the last Download page#####\n",
    "\n",
    "#opening the page\n",
    "r = br.open(down_page_2)\n",
    "\n",
    "#reading the page\n",
    "orders_html = br.response().read()\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(orders_html,'html.parser')\n",
    "\n",
    "down_link = soup.find_all(\"input\", {\"name\": \"download1\"})\n",
    "\n",
    "print('your download links are now ready . . .')\n",
    "label = ['link 1', 'link 2', 'link 3', 'link 4', 'link 5']\n",
    "\n",
    "for i in down_link:\n",
    "        print (i['value'])\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
